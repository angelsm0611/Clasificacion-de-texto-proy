{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_json_directory(directory_path, output_csv='dataset.csv'):\n",
    "    \"\"\"\n",
    "    Processes all JSON files in the given directory to create a binary classification dataset.\n",
    "    - Extracts abstracts as complex (label 1)\n",
    "    - Extracts adaptations as simple (label 0)\n",
    "    - Saves the result to a CSV file.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Traverse the nested structure\n",
    "            for q_id in data:\n",
    "                question_data = data[q_id]\n",
    "                # Find PMID keys\n",
    "                pmid_keys = [k for k in question_data if k.startswith('PMID_')]\n",
    "                for pmid in pmid_keys:\n",
    "                    pmid_data = question_data[pmid]\n",
    "                    \n",
    "                    # Extract abstract\n",
    "                    if 'abstract' in pmid_data:\n",
    "                        abstract_sentences = pmid_data['abstract']\n",
    "                        # Sort sentence keys by number (e.g., Sentence_1, Sentence_2)\n",
    "                        sorted_abstract_keys = sorted(\n",
    "                            abstract_sentences.keys(),\n",
    "                            key=lambda x: int(x.split('_')[1])\n",
    "                        )\n",
    "                        abstract_text = ' '.join(abstract_sentences[k] for k in sorted_abstract_keys)\n",
    "                        texts.append(abstract_text)\n",
    "                        labels.append(1)\n",
    "                    \n",
    "                    # Extract adaptations\n",
    "                    if 'adaptations' in pmid_data:\n",
    "                        adaptations = pmid_data['adaptations']\n",
    "                        for adapt_key in adaptations:\n",
    "                            adapt_sentences = adaptations[adapt_key]\n",
    "                            # Sort sentence keys by number\n",
    "                            sorted_adapt_keys = sorted(\n",
    "                                adapt_sentences.keys(),\n",
    "                                key=lambda x: int(x.split('_')[1])\n",
    "                            )\n",
    "                            adapt_text = ' '.join(adapt_sentences[k] for k in sorted_adapt_keys)\n",
    "                            texts.append(adapt_text)\n",
    "                            labels.append(0)\n",
    "    \n",
    "process_json_directory(\".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da54259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
